{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AN INVOICE CLASSIFIER"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This application is used to take in a pdf from a user and classify it according to the sender of the pdf, its category/type of invoice and type/category of goods administered"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First of all is to acknowledge the type of formats that can come from the user as an input. The input(invoice) can come as one in two formats (*image or pdf*). The application should be able to take in any of the two formats."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this context, we are to set the targets locally since there is an assumption that their is a use of a webiste for uploading the target. Without the website, the files will be locally stored in this repository for analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The program will first work with pictures to form the model then it will include PDF's later to scan through."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IMPLEMENTATION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importation of libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential\n",
    "import os as os\n",
    "import sys as sys\n",
    "import PIL\n",
    "import PIL.Image\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading the csv holding the training data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_csv(\"files\\data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gets total number of images in directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "\n",
    "# Define the directory path where your images are located\n",
    "directory_path = 'files/'  # Replace with the actual directory path\n",
    "\n",
    "# Define a list of image file extensions (add more if needed)\n",
    "image_extensions = ['*.jpg', '*.jpeg', '*.png', '*.gif', '*.bmp']\n",
    "\n",
    "# Initialize a variable to store the count of images\n",
    "total_image_count = 0\n",
    "\n",
    "# Loop through each image extension and count the images\n",
    "for extension in image_extensions:\n",
    "    pattern = os.path.join(directory_path, extension)\n",
    "    image_files = glob.glob(pattern)\n",
    "    total_image_count += len(image_files)\n",
    "\n",
    "# Print the total number of images\n",
    "print(f'Total number of images in the directory: {total_image_count}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We then save the photos is a tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For every image in the directory we save it to a tensor\n",
    "image_tensors = []\n",
    "for extension in image_extensions:\n",
    "    pattern = os.path.join(directory_path, extension)\n",
    "    image_files = glob.glob(pattern)\n",
    "    for file in image_files:\n",
    "        image = tf.io.read_file(file)\n",
    "        image = tf.image.decode_jpeg(image, channels=3)\n",
    "        image = tf.image.convert_image_dtype(image, tf.float32)\n",
    "        image_tensors.append(image)\n",
    "\n",
    "desired_size = (256, 256)\n",
    "resized_image = tf.image.resize(image_tensors, desired_size)\n",
    "\n",
    "# You can also normalize the image pixels to a specific range (0 to 1):\n",
    "normalized_image = resized_image / 255.0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### printing some images in the tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the image (optional)\n",
    "loop = 2\n",
    "i=0\n",
    "while i < loop:\n",
    "    plt.imshow(image_tensors[i])\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "    i += 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now we can start processing the photos. \n",
    "The idea is we use neuron network to classify the image according to the recepient of the invoice. It can be companies or individuals.\n",
    "The csv holds the actual recipient of the invoice and the image is the invoice itself.\n",
    "The model should be able to analyse the image and pinpoint the recipient of the invoice.\n",
    "The model should be able to classify the image according to the recipient of the invoice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the images in a nuero network\n",
    "# Define the model \n",
    "model = Sequential([\n",
    "    layers.Conv2D(16, 3, padding='same', activation='relu'),\n",
    "    layers.MaxPooling2D(),\n",
    "    layers.Conv2D(32, 3, padding='same', activation='relu'),\n",
    "    layers.MaxPooling2D(),\n",
    "    layers.Conv2D(64, 3, padding='same', activation='relu'),\n",
    "    layers.MaxPooling2D(),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.Dense(1)\n",
    "])\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam',\n",
    "                loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "                metrics=['accuracy'])\n",
    "# Train the model\n",
    "model.fit(normalized_image, epochs=10)\n",
    "# Save the model\n",
    "model.save('model.h5')\n",
    "# Load the model\n",
    "model = tf.keras.models.load_model('model.h5')\n",
    "# Make predictions\n",
    "predictions = model.predict(normalized_image)\n",
    "# Print the predictions\n",
    "print(predictions)\n",
    "# Print the actual labels\n",
    "print(labels)\n",
    "# set the printing of predictions and labels in a loop\n",
    "loop = 3\n",
    "i=0\n",
    "while i < loop:\n",
    "    print(predictions[i])\n",
    "    print(labels[i])\n",
    "    plt.imshow(image_tensors[i])\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "    i += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Data cardinality is ambiguous:\n  x sizes: 2\n  y sizes: 0\nMake sure all arrays contain the same number of samples.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[34], line 61\u001b[0m\n\u001b[0;32m     56\u001b[0m model\u001b[39m.\u001b[39mcompile(optimizer\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39madam\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[0;32m     57\u001b[0m               loss\u001b[39m=\u001b[39mtf\u001b[39m.\u001b[39mkeras\u001b[39m.\u001b[39mlosses\u001b[39m.\u001b[39mBinaryCrossentropy(from_logits\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m),\n\u001b[0;32m     58\u001b[0m               metrics\u001b[39m=\u001b[39m[\u001b[39m'\u001b[39m\u001b[39maccuracy\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[0;32m     60\u001b[0m \u001b[39m# Train the model\u001b[39;00m\n\u001b[1;32m---> 61\u001b[0m model\u001b[39m.\u001b[39;49mfit(image_tensors, labels, epochs\u001b[39m=\u001b[39;49m\u001b[39m10\u001b[39;49m)\n\u001b[0;32m     63\u001b[0m \u001b[39m# Save the model\u001b[39;00m\n\u001b[0;32m     64\u001b[0m model\u001b[39m.\u001b[39msave(\u001b[39m'\u001b[39m\u001b[39mmodel.h5\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\keras\\src\\engine\\data_adapter.py:1950\u001b[0m, in \u001b[0;36m_check_data_cardinality\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m   1943\u001b[0m     msg \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m  \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m sizes: \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[0;32m   1944\u001b[0m         label,\n\u001b[0;32m   1945\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m, \u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mjoin(\n\u001b[0;32m   1946\u001b[0m             \u001b[39mstr\u001b[39m(i\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m]) \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m tf\u001b[39m.\u001b[39mnest\u001b[39m.\u001b[39mflatten(single_data)\n\u001b[0;32m   1947\u001b[0m         ),\n\u001b[0;32m   1948\u001b[0m     )\n\u001b[0;32m   1949\u001b[0m msg \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mMake sure all arrays contain the same number of samples.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m-> 1950\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(msg)\n",
      "\u001b[1;31mValueError\u001b[0m: Data cardinality is ambiguous:\n  x sizes: 2\n  y sizes: 0\nMake sure all arrays contain the same number of samples."
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, Sequential\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import glob\n",
    "\n",
    "# Define the directory path where your images are located\n",
    "directory_path = 'files/'  # Replace with the actual directory path\n",
    "\n",
    "# Define a list of image file extensions (add more if needed)\n",
    "image_extensions = ['*.jpg', '*.jpeg', '*.png', '*.gif', '*.bmp']\n",
    "\n",
    "# Initialize a variable to store the count of images\n",
    "total_image_count = 0\n",
    "\n",
    "# Loop through each image extension and count the images\n",
    "for extension in image_extensions:\n",
    "    pattern = os.path.join(directory_path, extension)\n",
    "    image_files = glob.glob(pattern)\n",
    "    total_image_count += len(image_files)\n",
    "\n",
    "# Create lists to store image data and labels\n",
    "image_data = []  # Store your image data here\n",
    "labels = []  # Store corresponding labels here\n",
    "\n",
    "# Load and preprocess images\n",
    "for extension in image_extensions:\n",
    "    pattern = os.path.join(directory_path, extension)\n",
    "    image_files = glob.glob(pattern)\n",
    "    for img_path in image_files:\n",
    "        img = plt.imread(img_path)\n",
    "        img = tf.image.resize(img, (256, 256))  # Resize the image if needed\n",
    "        img = img / 255.0  # Normalize pixel values to [0, 1]\n",
    "        image_data.append(img)\n",
    "        # Assuming you have a way to determine labels for each image, append them to 'labels' list.\n",
    "        # Example: labels.append(0) for class 0, labels.append(1) for class 1, and so on.\n",
    "\n",
    "# Convert lists to TensorFlow tensors\n",
    "image_tensors = tf.convert_to_tensor(image_data)\n",
    "labels = tf.convert_to_tensor(labels)\n",
    "\n",
    "# Define the model\n",
    "model = Sequential([\n",
    "    layers.Conv2D(16, 3, padding='same', activation='relu'),\n",
    "    layers.MaxPooling2D(),\n",
    "    layers.Conv2D(32, 3, padding='same', activation='relu'),\n",
    "    layers.MaxPooling2D(),\n",
    "    layers.Conv2D(64, 3, padding='same', activation='relu'),\n",
    "    layers.MaxPooling2D(),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.Dense(1)\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(image_tensors, labels, epochs=10)\n",
    "\n",
    "# Save the model\n",
    "model.save('model.h5')\n",
    "\n",
    "# Load the model\n",
    "loaded_model = tf.keras.models.load_model('model.h5')\n",
    "\n",
    "# Make predictions\n",
    "predictions = loaded_model.predict(image_tensors)\n",
    "\n",
    "# Print the predictions\n",
    "print(predictions)\n",
    "\n",
    "# Print the actual labels\n",
    "print(labels)\n",
    "\n",
    "# Display some images and their predictions (you can adjust 'loop' as needed)\n",
    "loop = min(3, len(image_data))\n",
    "for i in range(loop):\n",
    "    print(predictions[i])\n",
    "    print(labels[i])\n",
    "    plt.imshow(image_data[i])\n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fulldf= pd.conca"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
