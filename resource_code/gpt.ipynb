{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, Sequential\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import glob\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the directory path where your images are located\n",
    "directory_path = 'files/'  # Replace with the actual directory path\n",
    "\n",
    "# Define a list of image file extensions (add more if needed)\n",
    "image_extensions = ['*.jpg', '*.jpeg', '*.png', '*.gif', '*.bmp']\n",
    "\n",
    "# Initialize a variable to store the count of images\n",
    "total_image_count = 0\n",
    "\n",
    "# Loop through each image extension and count the images\n",
    "for extension in image_extensions:\n",
    "    pattern = os.path.join(directory_path, extension)\n",
    "    image_files = glob.glob(pattern)\n",
    "    total_image_count += len(image_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create lists to store image data and labels\n",
    "image_data = []  # Store your image data here\n",
    "labels = []  # Store corresponding labels here\n",
    "\n",
    "# Load and preprocess images\n",
    "for extension in image_extensions:\n",
    "    pattern = os.path.join(directory_path, extension)\n",
    "    image_files = glob.glob(pattern)\n",
    "    for img_path in image_files:\n",
    "        img = plt.imread(img_path)\n",
    "        img = tf.image.resize(img, (256, 256))  # Resize the image if needed\n",
    "        img = img / 255.0  # Normalize pixel values to [0, 1]\n",
    "        image_data.append(img)\n",
    "        # Assuming you have a way to determine labels for each image, append them to 'labels' list.\n",
    "        # Example: labels.append(0) for class 0, labels.append(1) for class 1, and so on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 256, 256, 3)\n",
      "(0,)\n"
     ]
    }
   ],
   "source": [
    "# Convert lists to TensorFlow tensors\n",
    "image_tensors = tf.convert_to_tensor(image_data)\n",
    "labels = tf.convert_to_tensor(labels)\n",
    "\n",
    "# Define the model\n",
    "model = Sequential([\n",
    "    layers.Conv2D(16, 3, padding='same', activation='relu'),\n",
    "    layers.MaxPooling2D(),\n",
    "    layers.Conv2D(32, 3, padding='same', activation='relu'),\n",
    "    layers.MaxPooling2D(),\n",
    "    layers.Conv2D(64, 3, padding='same', activation='relu'),\n",
    "    layers.MaxPooling2D(),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.Dense(1)\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "print(image_tensors.shape)\n",
    "print(labels.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Data cardinality is ambiguous:\n  x sizes: 2\n  y sizes: 0\nMake sure all arrays contain the same number of samples.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m# Train the model\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m model\u001b[39m.\u001b[39;49mfit(image_tensors, labels, epochs\u001b[39m=\u001b[39;49m\u001b[39m10\u001b[39;49m)\n\u001b[0;32m      4\u001b[0m \u001b[39m# Save the model\u001b[39;00m\n\u001b[0;32m      5\u001b[0m model\u001b[39m.\u001b[39msave(\u001b[39m'\u001b[39m\u001b[39mmodel.h5\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\keras\\src\\engine\\data_adapter.py:1950\u001b[0m, in \u001b[0;36m_check_data_cardinality\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m   1943\u001b[0m     msg \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m  \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m sizes: \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[0;32m   1944\u001b[0m         label,\n\u001b[0;32m   1945\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m, \u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mjoin(\n\u001b[0;32m   1946\u001b[0m             \u001b[39mstr\u001b[39m(i\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m]) \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m tf\u001b[39m.\u001b[39mnest\u001b[39m.\u001b[39mflatten(single_data)\n\u001b[0;32m   1947\u001b[0m         ),\n\u001b[0;32m   1948\u001b[0m     )\n\u001b[0;32m   1949\u001b[0m msg \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mMake sure all arrays contain the same number of samples.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m-> 1950\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(msg)\n",
      "\u001b[1;31mValueError\u001b[0m: Data cardinality is ambiguous:\n  x sizes: 2\n  y sizes: 0\nMake sure all arrays contain the same number of samples."
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "model.fit(image_tensors, labels, epochs=10)\n",
    "\n",
    "# Save the model\n",
    "model.save('model.h5')\n",
    "\n",
    "# Load the model\n",
    "loaded_model = tf.keras.models.load_model('model.h5')\n",
    "\n",
    "# Make predictions\n",
    "predictions = loaded_model.predict(image_tensors)\n",
    "\n",
    "# Print the predictions\n",
    "print(predictions)\n",
    "\n",
    "# Print the actual labels\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display some images and their predictions (you can adjust 'loop' as needed)\n",
    "loop = min(3, len(image_data))\n",
    "for i in range(loop):\n",
    "    print(predictions[i])\n",
    "    print(labels[i])\n",
    "    plt.imshow(image_data[i])\n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import glob\n",
    "\n",
    "# Define the directory path where your images are located\n",
    "directory_path = 'path_to_your_directory'  # Replace with the actual directory path\n",
    "\n",
    "# Define a list of image file extensions (add more if needed)\n",
    "image_extensions = ['*.jpg', '*.jpeg', '*.png', '*.gif', '*.bmp']\n",
    "\n",
    "# Initialize lists to store image data and labels\n",
    "image_data = []  # Store your image data here\n",
    "labels = []  # Store corresponding labels here\n",
    "\n",
    "# Load and preprocess images\n",
    "for extension in image_extensions:\n",
    "    pattern = os.path.join(directory_path, extension)\n",
    "    image_files = glob.glob(pattern)\n",
    "    for img_path in image_files:\n",
    "        img = plt.imread(img_path)\n",
    "        img = tf.image.resize(img, (256, 256))  # Resize the image if needed\n",
    "        img = img / 255.0  # Normalize pixel values to [0, 1]\n",
    "        image_data.append(img)\n",
    "        \n",
    "        # Assuming you have a way to determine labels for each image, append them to 'labels' list.\n",
    "        # Example: labels.append(0) for class 0, labels.append(1) for class 1, and so on.\n",
    "        # Make sure the number of labels matches the number of images.\n",
    "        labels.append(your_label)  # Replace 'your_label' with the actual label for the current image.\n",
    "\n",
    "# Convert lists to TensorFlow tensors\n",
    "image_tensors = tf.convert_to_tensor(image_data)\n",
    "labels = tf.convert_to_tensor(labels)\n",
    "\n",
    "# Now, you have both input data (image_tensors) and target data (labels) with the same number of samples, and you can train your model.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
