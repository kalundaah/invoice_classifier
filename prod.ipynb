{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install pandas\n",
    "# !pip install numpy\n",
    "# !pip install opencv-python\n",
    "# !pip install pytesseract\n",
    "# !dnf install tesseract-ocr\n",
    "# !dnf install poppler-utils\n",
    "# !pip install -U spacy\n",
    "# !python -m spacy download en_core_web_sm\n",
    "# !pip install fitz\n",
    "# !pip install PyPDF2 pdf2image\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating a model that takes in the images and processes them\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Collect all PDF's and change them to image format\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image extraction completed.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import PyPDF2\n",
    "from pdf2image import convert_from_path\n",
    "\n",
    "# Path to PDFs\n",
    "directory_path = './Prod files/'\n",
    "\n",
    "# Extension to be captured\n",
    "pdf_extension = '*.pdf'\n",
    "\n",
    "# Create a directory to save the extracted images\n",
    "output_directory = './extracted_images/'\n",
    "os.makedirs(output_directory, exist_ok=True)\n",
    "\n",
    "def extract_images_from_pdf(pdf_path, output_dir):\n",
    "    try:\n",
    "        # Open the PDF file using PyPDF2\n",
    "        with open(pdf_path, 'rb') as pdf_file:\n",
    "            full_name = os.path.basename(pdf_path)\n",
    "            file_name = os.path.splitext(full_name)\n",
    "            pdf_reader = PyPDF2.PdfReader(pdf_file)\n",
    "            num_pages = len(pdf_reader.pages)\n",
    "\n",
    "            # Convert each page of the PDF to images using pdf2image\n",
    "            images = convert_from_path(pdf_path)\n",
    "\n",
    "            for page_num, image in enumerate(images, start=1):\n",
    "                # Save the image as PNG\n",
    "                image_filename = os.path.join(output_dir, f'{file_name[0]}page{page_num}.png')\n",
    "                image.save(image_filename, 'PNG')\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error extracting images from {pdf_path}: {str(e)}\")\n",
    "\n",
    "# Find PDF files in the directory\n",
    "pdf_files = glob.glob(os.path.join(directory_path, pdf_extension))\n",
    "\n",
    "# Loop through each PDF and extract images\n",
    "for pdf_path in pdf_files:\n",
    "    extract_images_from_pdf(pdf_path, output_directory)\n",
    "\n",
    "print(\"Image extraction completed.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## extract the text from the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image 1\n",
      "Image 2\n",
      "Image 3\n",
      "Image 4\n",
      "Image 5\n",
      "Image 6\n",
      "Image 7\n",
      "Image 8\n",
      "Image 9\n",
      "Image 10\n"
     ]
    }
   ],
   "source": [
    "import pytesseract\n",
    "import cv2\n",
    "import os\n",
    "import glob\n",
    "\n",
    "# Define the directory path where your invoice images are located\n",
    "directory_path = \"./extracted_images/\"\n",
    "\n",
    "# Extensions to be captured\n",
    "image_extensions = ['*.jpg', '*.png']\n",
    "\n",
    "# List to store the captured data\n",
    "image_data = []\n",
    "\n",
    "i = 0\n",
    "\n",
    "# Tesseract configuration options (you can customize these)\n",
    "custom_config = r'--oem 3 --psm 6'\n",
    "\n",
    "for extension in image_extensions:\n",
    "    pattern = os.path.join(directory_path, extension)\n",
    "    image_files = glob.glob(pattern)\n",
    "    for img_path in image_files:\n",
    "        full_name = os.path.basename(img_path)\n",
    "        file_name = os.path.splitext(full_name)\n",
    "\n",
    "        # Load image\n",
    "        img = cv2.imread(img_path)\n",
    "\n",
    "        # Convert image to grayscale\n",
    "        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        # Apply threshold to convert to binary image\n",
    "        threshold_img = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)[1]\n",
    "\n",
    "        # Additional pre-processing steps can be added here (e.g., resizing, denoising)\n",
    "\n",
    "        # Pass the pre-processed image through pytesseract with custom config\n",
    "        text = pytesseract.image_to_string(threshold_img, config=custom_config, lang='eng')\n",
    "\n",
    "        name = file_name[0]\n",
    "\n",
    "        # Print the extracted text\n",
    "        image_data.append([name, text])\n",
    "        i += 1\n",
    "        print('Image', i)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save the extracted text in a df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "text = pd.DataFrame(image_data,columns=(\"image_name\",\"text\"))\n",
    "text.to_csv(\"./Prod files/extracted_text.csv\")\n",
    "text.to_json(\"./Prod files/extracted_text.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Begin the Training process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This also entails analysing your data and understanding it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The formats of the extracted photos look as follows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating mock entries for the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one big list for all the data\n",
    "full_list = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from faker import Faker\n",
    "faker = Faker()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chandarana"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Chandarana Format:\n",
    "Doc No : Numbers\n",
    "\n",
    "Supplier: Numbers\n",
    "\n",
    "Ref No : KES +/- Numbers\n",
    "\n",
    "Net: KES +/- Numbers\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### usable functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def supplierrefgen():\n",
    "    year = str(random.randint(2000, 2023))\n",
    "    month = str(random.randint(1, 12))\n",
    "    invnos = str(random.randint(1,100000000))\n",
    "    placer = str(year+month+invnos)\n",
    "    return placer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def docnogen():\n",
    "    placer = str(random.randint(1, 1000000))\n",
    "    return placer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grossgen():\n",
    "    currency = \"KES \"\n",
    "    choice =  random.choice([\"-\", \"\"])\n",
    "    amt = str(random.randint(100, 100000))\n",
    "    placer = str(currency+choice+amt)\n",
    "    return placer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def netgen():\n",
    "    currency = \"KES -\"\n",
    "    amt = str(random.randint(100, 100000))\n",
    "    placer = str(currency+amt)\n",
    "    return placer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating mock data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from faker import Faker\n",
    "import random\n",
    "\n",
    "# Initialize Faker\n",
    "fake = Faker()\n",
    "\n",
    "# Initialize empty lists to store mock data\n",
    "mock_invoices = []\n",
    "\n",
    "# Labels list\n",
    "labels =[]\n",
    "i = 0\n",
    "# Generate and store 1000 mock invoices\n",
    "for i in range(1000):\n",
    "    # Generate random data for labels\n",
    "\n",
    "    \n",
    "    # Generate the invoice text with labels and multiple rows\n",
    "    rows = []\n",
    "    for _ in range(50):  # Generate 50 rows\n",
    "        docno = docnogen()\n",
    "        supplier_ref = supplierrefgen()\n",
    "        gross = grossgen()\n",
    "        net = netgen()\n",
    "        row = f\"{docno} {supplier_ref} {gross} {net}\"\n",
    "        rows.append(row)\n",
    "        labels.append([i+1,docno,supplier_ref,gross,net])\n",
    "    newline = \"\\n\\t\"\n",
    "    \n",
    "\n",
    "    invoice_text = f\"\"\"\n",
    "    Remittance Advice - Chandarana Dec 21page1,\"CHANDARANA SUPERMARKET LTD\n",
    "    30386 Paid By: Accounts\n",
    "    KENYA\n",
    "\n",
    "    REMITTANCE ADVICE 1149720 Original\n",
    "    Ht [Date [Paid Doc. | Doc. No. Supplier Ref No Gross Amount Net Amount\n",
    "    {newline.join(rows)} \n",
    "    KES 11,891,067.58 KES 9,030.65] KES 11,882,036.93\n",
    "    Transfer Date: Bank Trans. Total: KES 11,882,036.93\n",
    "    18/01/2022\n",
    "    Total Amount: KES 11,882,036.93\n",
    "    Name Of Collector / ID Date Collected Signature of Vendor |\n",
    "    \"\"\"\n",
    "    \n",
    "    # Append the generated invoice text to the list\n",
    "    mock_invoices.append([i+1, invoice_text])\n",
    "    full_list.append([i+1, invoice_text])\n",
    "    i=i+1\n",
    "\n",
    "# Print the first mock invoice for reference (will use the list index for id)\n",
    "# print(mock_invoices[0])\n",
    "print(\"Finished\")\n",
    "\n",
    "# Create a DataFrame from the mock invoices list\n",
    "chandaranamockdf = pd.DataFrame(mock_invoices, columns=(\"id\", \"sentence\"))\n",
    "\n",
    "# You can also save the labels (docno, supplier_ref, gross, net) in a separate DataFrame if needed.\n",
    "chandaranalabel = pd.DataFrame(labels,columns=(\"id\",\"document_no\",\"supplier_ref\",\"gross\",\"net\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "chandaranalabel.to_csv(\"./Prod files/chandaranalabels.csv\",index=False)\n",
    "chandaranamockdf.to_csv('./Prod files/chandaranamock.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Carrefour"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Carrefour Format:\n",
    "Company Name : Name\n",
    "\n",
    "Inv Nos : Nos/Let/let\n",
    "\n",
    "Date: dd-mm-yy\n",
    "\n",
    "Remarks : Numbers/DEFAULT AGREEMENT\n",
    "\n",
    "Amt: Number +/-\n",
    "\n",
    "Company_name Total : Numbers\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from faker import Faker\n",
    "import random\n",
    "faker = Faker()\n",
    "\n",
    "def companygen():\n",
    "    name = faker.company()\n",
    "    return name\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def invgen():\n",
    "\n",
    "    def chance1():\n",
    "        front = str(random.randint(10000000, 99999999))\n",
    "        # Generate two random uppercase letters\n",
    "        letters = ''.join(random.choice('ABCDEFGHIJKLMNOPQRSTUVWXYZ') for _ in range(2))\n",
    "        \n",
    "        # Generate a random number between 10000 and 99999\n",
    "        number = str(random.randint(0, 9))\n",
    "\n",
    "        last = ''.join(random.choice('ABCDEFGHIJKLMNOPQRSTUVWXYZ') for _ in range(3))\n",
    "        \n",
    "        # Concatenate the letters and number to create the invoice number\n",
    "        invoice_number = f\"{front}/{letters}{number}/{last}\"\n",
    "        return invoice_number\n",
    "    \n",
    "    def chance2():\n",
    "        front = str(random.randint(10000000, 99999999))\n",
    "        invoice_number = f\"{front}\"\n",
    "        return invoice_number\n",
    "    \n",
    "    inv1 = chance1()\n",
    "    inv2 = chance2()\n",
    "    invresult = random.choice([inv1,inv2])\n",
    "    \n",
    "    placer = ''.join(invresult)\n",
    "    return placer\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dategen():\n",
    "    day = str(random.randint(1, 28))\n",
    "    month= str(random.randint(1, 12))\n",
    "    year = str(random.randint(2000, 2040))\n",
    "    placer = f\"{day}-{month}-{year}\"\n",
    "    return placer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remarksgen():\n",
    "    percentage = str(random.randint(0, 100))\n",
    "    numbers = str(random.randint(1, 3))\n",
    "    numbers2 = str(random.randint(100, 199))\n",
    "    choice1 = f\"DEFAULT AGREEMENT ({percentage}%) 00{numbers} {numbers2}\"\n",
    "    choice2 = \"DEFAULT AGREEMENT (EXEMPTED)\"\n",
    "    remark = random.choice([choice1,choice2])\n",
    "    placer = random.choice([remark,\"\"])\n",
    "    return placer\n",
    "\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def amountgen():\n",
    "    value = str(random.randint(100, 10000))\n",
    "    return value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def totalgen():\n",
    "    value = str(random.randint(10000, 999999))\n",
    "    return value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from faker import Faker\n",
    "import random\n",
    "\n",
    "# Initialize Faker\n",
    "fake = Faker()\n",
    "\n",
    "# Initialize empty lists to store mock data\n",
    "mock_invoices = []\n",
    "\n",
    "# Labels list\n",
    "invlabels =[]\n",
    "totallabels = []\n",
    "i = 0\n",
    "# Generate and store 1000 mock invoices\n",
    "for i in range(1000):\n",
    "    # Generate random data for labels\n",
    "\n",
    "    \n",
    "    # Generate the invoice text with labels and multiple rows\n",
    "    rows = []\n",
    "    for _ in range(50):  # Generate 50 rows\n",
    "        companyname = companygen()\n",
    "        total = totalgen()\n",
    "        row = f\"{companyname}\"\n",
    "        rows.append(row)\n",
    "        for _ in range(10):\n",
    "            invnos = invgen()\n",
    "            date = dategen()\n",
    "            remark = remarksgen()\n",
    "            amt = amountgen()\n",
    "            row = f\"{invnos} {date} {remark} {amt}\"\n",
    "            rows.append(row)\n",
    "            invlabels.append([i+1,companyname,invnos,date,remark,amt])\n",
    "        row = f\"{companyname} Total : {total}\"\n",
    "        rows.append(row)\n",
    "        totallabels.append([i+1,companyname,total])\n",
    "    newline = \"\\n\\t\"\n",
    "    \n",
    "\n",
    "    invoice_text = f\"\"\"\n",
    "    Payment Attachment Page - 1\n",
    "    Payment No. : 130595\n",
    "    AICNo: 2298452 UNGALIMITED Payment Dt.: 28-02-22\n",
    "    ee AMoUNtPaid =\n",
    "    Company Invoice Number Invoice Date Remarks\n",
    "    (KES)\n",
    "    {newline.join(rows)} \n",
    "    UNGA LIMITED Total : $,898,752.53\n",
    "    \"\"\"\n",
    "    \n",
    "    # Append the generated invoice text to the list\n",
    "    mock_invoices.append([i+1, invoice_text])\n",
    "    i = i + 1\n",
    "    \n",
    "\n",
    "# Print the first mock invoice for reference (will use the list index for id)\n",
    "# print(mock_invoices[0])\n",
    "print(\"Finished\")\n",
    "\n",
    "# Create a DataFrame from the mock invoices list\n",
    "carrefourmockdf = pd.DataFrame(mock_invoices, columns=(\"id\", \"sentence\"))\n",
    "\n",
    "# You can also save the labels (docno, supplier_ref, gross, net) in a separate DataFrame if needed.\n",
    "carrefourlabel = pd.DataFrame(labels,columns=(\"id\",\"document_no\",\"supplier_ref\",\"gross\",\"net\"))\n",
    "\n",
    "carrefourtotals = pd.DataFrame(totallabels,columns=('id',\"name\",\"totals\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "carrefourlabel.to_csv(\"./Prod files/carrefourlabels.csv\",index=False)\n",
    "carrefourmockdf.to_csv('./Prod files/carrefourmock.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Jumra"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Jumra Format:\n",
    "Paid doc : A/P\n",
    "\n",
    "Doc No : Credit memo/Invoice\n",
    "\n",
    "Date: dd/mm/yy\n",
    "\n",
    "Invoice amount : +/- Numbers\n",
    "\n",
    "Witheld: +/- Numbers\n",
    "\n",
    "Amt : +/- Numbers\n",
    "\n",
    "outstanding: +/- Numbers\n",
    "\n",
    "\n",
    "Document amount due: KES Numbers\n",
    "\n",
    "Total amount due: KES Numbers\n",
    "\n",
    "\n",
    "`To be done later`\n",
    "\n",
    "Account Name: Bank name\n",
    "\n",
    "Transfer date: dd/mm/yy\n",
    "\n",
    "reference: rtgs\n",
    "\n",
    "Amount: Numbers\n",
    "\n",
    "\n",
    "Bank transfer total: KES Numbers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from faker import Faker\n",
    "faker = Faker()\n",
    "\n",
    "def docgen():\n",
    "    placer = random.choice([\"Credit memo\",\"Invoice\"])\n",
    "    return placer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N28468421\n"
     ]
    }
   ],
   "source": [
    "def invnosgen():\n",
    "    nos = str(random.randint(20000000, 29999999))\n",
    "    placer=f\"N{nos}\"\n",
    "    return placer\n",
    "\n",
    "x= invnosgen()\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dategen():\n",
    "    day = str(random.randint(1, 28))\n",
    "    month= str(random.randint(1, 12))\n",
    "    year = str(random.randint(2000, 2040))\n",
    "    placer = f\"{day}/{month}/{year}\"\n",
    "    return placer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-41263.51\n"
     ]
    }
   ],
   "source": [
    "def invamtgen():\n",
    "    sign = random.choice([\"-\",\"\"])\n",
    "    amt = str(round(random.uniform(10000, 99999), 2))\n",
    "    placer = f\"{sign}{amt}\"\n",
    "    return placer\n",
    "\n",
    "x = invamtgen()\n",
    "print(x)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-441.35\n"
     ]
    }
   ],
   "source": [
    "def witheldamtgen():\n",
    "    sign = random.choice([\"-\",\"\"])\n",
    "    amt = str(round(random.uniform(1, 1000), 2))\n",
    "    placer = f\"{sign}{amt}\"\n",
    "    return placer\n",
    "\n",
    "x = witheldamtgen()\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "89479.74\n"
     ]
    }
   ],
   "source": [
    "def amtgen():\n",
    "    sign = random.choice([\"-\",\"\"])\n",
    "    amt = str(round(random.uniform(10000, 99999), 2))\n",
    "    placer = f\"{sign}{amt}\"\n",
    "    return placer\n",
    "\n",
    "x = amtgen()\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-5047.6\n"
     ]
    }
   ],
   "source": [
    "def outstandingamtgen():\n",
    "    sign = random.choice([\"-\",\"\"])\n",
    "    amt = str(round(random.uniform(1000, 9999), 2))\n",
    "    placer = f\"{sign}{amt}\"\n",
    "    return placer\n",
    "\n",
    "x = outstandingamtgen()\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5197525.05\n"
     ]
    }
   ],
   "source": [
    "def amountdue():\n",
    "    amt = str(round(random.uniform(100000, 9999999), 2))\n",
    "    placer = f\"{amt}\"\n",
    "    return placer\n",
    "\n",
    "x = amountdue()\n",
    "print(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from faker import Faker\n",
    "import random\n",
    "\n",
    "# Initialize Faker\n",
    "fake = Faker()\n",
    "\n",
    "# Initialize empty lists to store mock data\n",
    "mock_invoices = []\n",
    "\n",
    "# Labels list\n",
    "invlabels =[]\n",
    "totallabels = []\n",
    "i = 0\n",
    "# Generate and store 1000 mock invoices\n",
    "for i in range(1000):\n",
    "    # Generate random data for labels\n",
    "\n",
    "    total = totalgen()\n",
    "    name = companygen()\n",
    "    # Generate the invoice text with labels and multiple rows\n",
    "    rows = []\n",
    "    companyname = companygen()\n",
    "    for _ in range(50):  # Generate 50 rows\n",
    "        paid = \"A/P\"\n",
    "        doc = docgen()\n",
    "        nos = invnosgen()\n",
    "        date = dategen()\n",
    "        invamt = invamtgen()\n",
    "        withheld = witheldamtgen()\n",
    "        amt= amtgen()\n",
    "        outstanding = outstandingamtgen()\n",
    "        row = f\"{paid} {doc} {nos} {date} {invamt} {withheld} {amt} {outstanding}\"\n",
    "        rows.append(row)\n",
    "        labels.append([i+1,paid,doc,nos,date,invamt,withheld,amt,outstanding])\n",
    "    \n",
    "    totallabels.append([i+1,companyname,total])\n",
    "    newline = \"\\n\\t\"\n",
    "    \n",
    "\n",
    "    invoice_text = f\"\"\"\n",
    "    Jumbo complex, Mogadishu Road 7, 1523 10/02/2022\n",
    "    P.O Box 543 - 00606 _— TT\n",
    "    , Kenya Account. PIN Number - Supplier\n",
    "    PIN: P051414072z S086\n",
    "    Cheque Ne.\n",
    "    Haco Tiger Brands (EA) Ltd\n",
    "    \"\"P O Box 43903, 00100\"\" ;\n",
    "    Haco Tiger Brands (EA) Ltd\n",
    "    \"\"P O Box 43903, 00100\"\"\n",
    "    Payments Currency: KES\n",
    "    # Paid Doc Doc. No. Date Invoice Amount Withheld Amnt Amount Outstanding\n",
    "    {newline.join(rows)} \n",
    "    Bank Transfer\n",
    "    Account Name Transfer Date Reference Amount\n",
    "    VICTORIA COMMERCIAL BANK1 10/02/2022 rtgs 4,072,474.25\n",
    "    Bank Transfer Total: KES 4,072,474.25\n",
    "    Outgoing Payments - S086\n",
    "    Signature: Date: Total Payment Amount: KES 4,072,474.25\n",
    "    \"\"\"\n",
    "    \n",
    "    # Append the generated invoice text to the list\n",
    "    mock_invoices.append([i+1, invoice_text])\n",
    "    i = i + 1\n",
    "    \n",
    "\n",
    "# Print the first mock invoice for reference (will use the list index for id)\n",
    "# print(mock_invoices[0])\n",
    "print(\"Finished\")\n",
    "\n",
    "# Create a DataFrame from the mock invoices list\n",
    "jumradf = pd.DataFrame(mock_invoices, columns=(\"id\", \"sentence\"))\n",
    "\n",
    "# You can also save the labels (docno, supplier_ref, gross, net) in a separate DataFrame if needed.\n",
    "jumralabel = pd.DataFrame(labels,columns=(\"id\",\"paid\",\"doc\",\"nos\",\"date\",\"invamt\",\"withheld\",\"amt\",\"outstanding\"))\n",
    "\n",
    "jumratotals = pd.DataFrame(totallabels,columns=(\"id\",\"name\",\"totals\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "jumralabel.to_csv(\"./Prod files/jumralabels.csv\",index=False)\n",
    "jumradf.to_csv('./Prod files/jumramock.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PREPARATION FOR TRAINING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id         int64\n",
       "name      object\n",
       "totals    object\n",
       "dtype: object"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "carrefourtotals.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The df that are to be trained \n",
    "# jumradf\n",
    "# chandaranamockdf\n",
    "# carrefourmockdf\n",
    "# jumratotals\n",
    "# carrefourtotals\n",
    "# jumralabel\n",
    "# chandaranalabel\n",
    "# carrefourlabel\n",
    "\n",
    "import spacy\n",
    "\n",
    "nlp = spacy.blank(\"en\")\n",
    "\n",
    "\n",
    "ruler = nlp.add_pipe(\"entity_ruler\")\n",
    "jumrapatterns=[]\n",
    "chandaranapatterns = []\n",
    "carrefourpatterns = []\n",
    "\n",
    "i = 0 \n",
    "while i < (len(jumralabel)):\n",
    "    jumrapatterns.append({\"label\": \"Paid\",\"pattern\": jumralabel['paid'][i]})\n",
    "    jumrapatterns.append({\"label\": \"Document type\",\"pattern\": jumralabel['doc'][i]})\n",
    "    jumrapatterns.append({\"label\": \"Invoice Number\",\"pattern\": jumralabel['nos'][i]})\n",
    "    jumrapatterns.append({\"label\": \"Invoice Date\",\"pattern\": jumralabel['date'][i]})\n",
    "    jumrapatterns.append({\"label\": \"Invoice amount\",\"pattern\": jumralabel['invamt'][i]})\n",
    "    jumrapatterns.append({\"label\": \"Withheld amount\",\"pattern\": jumralabel['withheld'][i]})\n",
    "    jumrapatterns.append({\"label\": \"Amount\",\"pattern\": jumralabel['amt'][i]})\n",
    "    jumrapatterns.append({\"label\": \"Outstanding Amount\",\"pattern\": jumralabel['outstanding'][i]})\n",
    "    i = i+1\n",
    "\n",
    "i=0\n",
    "while i<len(jumratotals):\n",
    "    jumrapatterns.append({\"label\": \"Grand Total amount\",\"pattern\": jumratotals['totals'][i]})\n",
    "    i = i+1\n",
    "\n",
    "i=0\n",
    "while i<len(chandaranalabel):\n",
    "    chandaranapatterns.append({\"label\": \"Document Number\",\"pattern\": chandaranalabel['document_no'][i]})\n",
    "    chandaranapatterns.append({\"label\": \"Supplier reference\",\"pattern\": chandaranalabel['supplier_ref'][i]})\n",
    "    chandaranapatterns.append({\"label\": \"Gross amount\",\"pattern\": chandaranalabel['gross'][i]})\n",
    "    chandaranapatterns.append({\"label\": \"Net amount\",\"pattern\": chandaranalabel['net'][i]})\n",
    "    i = i+1\n",
    "\n",
    "i=0\n",
    "while i<len(carrefourlabel):\n",
    "    carrefourpatterns.append({\"label\": \"Document Number\",\"pattern\": carrefourlabel['document_no'][i]})\n",
    "    carrefourpatterns.append({\"label\": \"Supplier reference\",\"pattern\": carrefourlabel['supplier_ref'][i]})\n",
    "    carrefourpatterns.append({\"label\": \"Gross amount\",\"pattern\": carrefourlabel['gross'][i]})\n",
    "    carrefourpatterns.append({\"label\": \"Net amount\",\"pattern\": carrefourlabel['net'][i]})\n",
    "    i = i+1\n",
    "\n",
    "i=0\n",
    "while i<len(carrefourtotals):\n",
    "    carrefourpatterns.append({\"label\": \"Grand total amount\",\"pattern\": carrefourtotals['totals'][i]})\n",
    "    i = i+1\n",
    "\n",
    "\n",
    "\n",
    "ruler.add_patterns(carrefourpatterns)\n",
    "ruler.add_patterns(chandaranapatterns)\n",
    "ruler.add_patterns(jumrapatterns)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating training and entity data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "entities = []\n",
    "TRAIN_DATA = []\n",
    "\n",
    "while i < len(jumradf) :\n",
    "    sentence = jumradf['sentence'][i]\n",
    "    doc = nlp(sentence)\n",
    "    entities = set()\n",
    "    for ent in doc.ents:\n",
    "        entities.add((ent.label_, ent.start_char, ent.end_char))\n",
    "    unique_entities_list = list(entities)\n",
    "    TRAIN_DATA.append([sentence, {\"entities\": unique_entities_list}]) \n",
    "    i = i+1 \n",
    "\n",
    "i = 0\n",
    "while i < len(chandaranamockdf) :\n",
    "    sentence = chandaranamockdf['sentence'][i]\n",
    "    doc = nlp(sentence)\n",
    "    entities = set()\n",
    "    for ent in doc.ents:\n",
    "        entities.add((ent.label_, ent.start_char, ent.end_char))\n",
    "    unique_entities_list = list(entities)\n",
    "    TRAIN_DATA.append([sentence, {\"entities\": unique_entities_list}]) \n",
    "    i = i+1 \n",
    "\n",
    "i = 0\n",
    "while i < len(carrefourmockdf) :\n",
    "    sentence = carrefourmockdf['sentence'][i]\n",
    "    doc = nlp(sentence)\n",
    "    entities = set()\n",
    "    for ent in doc.ents:\n",
    "        entities.add((ent.label_, ent.start_char, ent.end_char))\n",
    "    unique_entities_list = list(entities)\n",
    "    TRAIN_DATA.append([sentence, {\"entities\": unique_entities_list}]) \n",
    "    i = i+1 \n",
    "\n",
    "\n",
    "# ent.text,ent.label_\n",
    "# print (TRAIN_DATA)\n",
    "print('finished')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import srsly\n",
    "import typer\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "\n",
    "import spacy\n",
    "from spacy.tokens import DocBin\n",
    "\n",
    "def convert(lang: str, TRAIN_DATA, output_path: Path):\n",
    "    nlp = spacy.blank(lang)\n",
    "    db = DocBin()\n",
    "    for text, annot in TRAIN_DATA:\n",
    "        doc = nlp.make_doc(text)\n",
    "        ents = []\n",
    "        for  label,start,end in annot[\"entities\"]:\n",
    "            start = int(start)\n",
    "            end = int(end)\n",
    "            span = doc.char_span(start, end, label=label)\n",
    "            if span is None:\n",
    "                msg = f\"Skipping entity [{start}, {end}, {label}] in the following text because the character span '{doc.text[start:end]}' does not align with token boundaries:\\n\\n{repr(text)}\\n\"\n",
    "                warnings.warn(msg)\n",
    "            else:\n",
    "                ents.append(span)\n",
    "        doc.ents = ents\n",
    "        db.add(doc)\n",
    "    db.to_disk(output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "convert(\"en\", TRAIN_DATA, \"./proddata/train.spacy\")\n",
    "convert(\"en\", TRAIN_DATA, \"./proddata/valid.spacy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;2m✔ Auto-filled config with all values\u001b[0m\n",
      "\u001b[38;5;2m✔ Saved config\u001b[0m\n",
      "config.cfg\n",
      "You can now add your data and train your pipeline:\n",
      "python -m spacy train config.cfg --paths.train ./train.spacy --paths.dev ./dev.spacy\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy init fill-config base_config.cfg config.cfg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;4mℹ Saving to output directory: prodmodel\u001b[0m\n",
      "\u001b[38;5;4mℹ Using CPU\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== Initializing pipeline ===========================\u001b[0m\n",
      "\u001b[38;5;2m✔ Initialized pipeline\u001b[0m\n",
      "\u001b[1m\n",
      "============================= Training pipeline =============================\u001b[0m\n",
      "\u001b[38;5;4mℹ Pipeline: ['tok2vec', 'ner']\u001b[0m\n",
      "\u001b[38;5;4mℹ Initial learn rate: 0.001\u001b[0m\n",
      "E    #       LOSS TOK2VEC  LOSS NER  ENTS_F  ENTS_P  ENTS_R  SCORE \n",
      "---  ------  ------------  --------  ------  ------  ------  ------\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy train config.cfg --paths.train ./proddata/train.spacy --paths.dev ./proddata/valid.spacy --output ./prodmodel/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
